

from google.colab import drive
drive.mount('/content/drive')
     
Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount("/content/drive", force_remount=True).

!pip install numpy==1.23.1
     
Requirement already satisfied: numpy==1.23.1 in /usr/local/lib/python3.10/dist-packages (1.23.1)

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
%matplotlib inline
import seaborn as sns
import cv2
import glob
import random
from os import listdir
from sklearn.metrics import classification_report
import tensorflow as tf
import keras.utils as image
     

import os
from PIL import Image

# create a list to store the images
images = []

# loop through the files in the folder
for file in os.listdir('/content/drive/MyDrive/New folder'):
  # check if the file is an image
  if file.endswith('.jpg') or file.endswith('.png'):
    # read the image and append it to the list
    img = Image.open(os.path.join('/content/drive/MyDrive/New folder', file))
    images.append(img)

     

import glob

breast_img = glob.glob('/content/drive/MyDrive/New folder/**/*.png', recursive = True)

for imgname in breast_img[:3]:
    print(imgname)
     
/content/drive/MyDrive/New folder/aeqpxjlbwu/101.png
/content/drive/MyDrive/New folder/aeqpxjlbwu/116.png
/content/drive/MyDrive/New folder/aeqpxjlbwu/118.png

non_fake_img = []
fake_img = []

for img in breast_img:
    if img[-5] == '0' :
        non_fake_img.append(img)

    elif img[-5] == '1' :
        fake_img.append(img)



     

non_fake_num = len(non_fake_img)  # No cancer
fake_num = len(fake_img)   # Cancer

total_img_num = non_fake_num + fake_num

print('Number of Images of  real: {}' .format(non_fake_num))   # images of Non cancer
print('Number of Images of fake : {}' .format(fake_num))   # images of cancer
print('Total Number of Images : {}' .format(total_img_num))
     
Number of Images of  real: 204
Number of Images of fake : 203
Total Number of Images : 407

data_insight_1 = pd.DataFrame({'state of fake' : ['0','1'],'Numbers of fake images' : [204,203]})
data_insight_1
     
state of fake	Numbers of fake images
0	0	204
1	1	203

import plotly.express as px

bar = px.bar(data_frame=data_insight_1, x = 'state of fake', y='Numbers of fake images', color='state of fake')
bar.update_layout(title_text='Number of fake images (1) and number of real images  (0)', title_x=0.5)
bar.show()
     

# @title Numbers of fake images

from matplotlib import pyplot as plt
data_insight_1['Numbers of fake images'].plot(kind='line', figsize=(8, 4), title='Numbers of fake images')
plt.gca().spines[['top', 'right']].set_visible(False)
     


# Import the load_img and img_to_array functions from tensorflow.keras.utils
from tensorflow.keras.utils import load_img, img_to_array

N_IDC = []
P_IDC = []

for img in breast_img:
    if img[-5] == '0' :
        N_IDC.append(img)

    elif img[-5] == '1' :
        P_IDC.append(img)
plt.figure(figsize = (15, 15))

some_non = np.random.randint(0, len(N_IDC), 18)
some_can = np.random.randint(0, len(P_IDC), 18)

s = 0
for num in some_non:

        # Use load_img instead of image.load_img
        img = load_img((N_IDC[num]), target_size=(100, 100))
        # Use img_to_array instead of image.img_to_array
        img = img_to_array(img)

        plt.subplot(6, 6, 2*s+1)
        plt.axis('off')
        plt.title('no fake')
        plt.imshow(img.astype('uint8'))
        s += 1
s = 1
for num in some_can:

        # Use load_img instead of image.load_img
        img = load_img((P_IDC[num]), target_size=(100, 100))
        # Use img_to_array instead of image.img_to_array
        img = img_to_array(img)

        plt.subplot(6, 6, 2*s)
        plt.axis('off')
        plt.title('IDC (+)')
        plt.imshow(img.astype('uint8'))
        s += 1

     


NewN_IDC=N_IDC[:204]
print(len(NewN_IDC))
print(len(P_IDC))
     
204
203


non_img_arr = []
can_img_arr = []

for img in NewN_IDC:
    n_img = cv2.imread(img, cv2.IMREAD_COLOR)
    n_img_size = cv2.resize(n_img, (50, 50), interpolation = cv2.INTER_LINEAR)
    non_img_arr.append([n_img_size, 0])

for img in P_IDC:
    c_img = cv2.imread(img, cv2.IMREAD_COLOR)
    c_img_size = cv2.resize(c_img, (50, 50), interpolation = cv2.INTER_LINEAR)
    can_img_arr.append([c_img_size, 1])
     

X = []
y = []

breast_img_arr = np.concatenate((non_img_arr[:12389], can_img_arr[:12389]))
random.shuffle(breast_img_arr)

for feature, label in breast_img_arr:
    X.append(feature)
    y.append(label)

X = np.array(X)
y = np.array(y)
     
<__array_function__ internals>:180: VisibleDeprecationWarning:

Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.


def describeData(a,b):
    print('Total number of images: {}'.format(len(a)))
    print('Number of IDC(-) Images: {}'.format(np.sum(b==0)))
    print('Number of IDC(+) Images: {}'.format(np.sum(b==1)))
    print('Image shape (Width, Height, Channels): {}'.format(a[0].shape))
describeData(X,y)
     
Total number of images: 407
Number of IDC(-) Images: 348
Number of IDC(+) Images: 59
Image shape (Width, Height, Channels): (50, 50, 3)

from sklearn.model_selection import train_test_split
X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.3)

from tensorflow.keras.utils import to_categorical
Y_train = to_categorical(Y_train, num_classes = 2)
Y_test = to_categorical(Y_test, num_classes = 2)

print("Training Data Shape:", X_train.shape)
print("Testing Data Shape:", X_test.shape)
     
Training Data Shape: (284, 50, 50, 3)
Testing Data Shape: (123, 50, 50, 3)

from sklearn.metrics import classification_report
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Conv2D,MaxPooling2D, Flatten, Dropout, BatchNormalization
from tensorflow.keras.optimizers import SGD
from tensorflow.keras.optimizers import Adam, SGD
from keras.metrics import binary_crossentropy
from tensorflow.keras.callbacks import EarlyStopping
from sklearn.metrics import confusion_matrix
import itertools
from tensorflow.keras.optimizers import Adam, Adamax
from tensorflow.keras import regularizers


     

from tensorflow.keras.applications.vgg19 import VGG19
from keras.models import Model
vgg_model=VGG19(input_shape=(50,50,3),include_top=False)
x=Flatten()(vgg_model.output)
prediction=Dense(2,activation='softmax')(x)
model=Model(inputs=vgg_model.input,outputs=prediction)
model.summary()
     
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_1 (InputLayer)        [(None, 50, 50, 3)]       0         
                                                                 
 block1_conv1 (Conv2D)       (None, 50, 50, 64)        1792      
                                                                 
 block1_conv2 (Conv2D)       (None, 50, 50, 64)        36928     
                                                                 
 block1_pool (MaxPooling2D)  (None, 25, 25, 64)        0         
                                                                 
 block2_conv1 (Conv2D)       (None, 25, 25, 128)       73856     
                                                                 
 block2_conv2 (Conv2D)       (None, 25, 25, 128)       147584    
                                                                 
 block2_pool (MaxPooling2D)  (None, 12, 12, 128)       0         
                                                                 
 block3_conv1 (Conv2D)       (None, 12, 12, 256)       295168    
                                                                 
 block3_conv2 (Conv2D)       (None, 12, 12, 256)       590080    
                                                                 
 block3_conv3 (Conv2D)       (None, 12, 12, 256)       590080    
                                                                 
 block3_conv4 (Conv2D)       (None, 12, 12, 256)       590080    
                                                                 
 block3_pool (MaxPooling2D)  (None, 6, 6, 256)         0         
                                                                 
 block4_conv1 (Conv2D)       (None, 6, 6, 512)         1180160   
                                                                 
 block4_conv2 (Conv2D)       (None, 6, 6, 512)         2359808   
                                                                 
 block4_conv3 (Conv2D)       (None, 6, 6, 512)         2359808   
                                                                 
 block4_conv4 (Conv2D)       (None, 6, 6, 512)         2359808   
                                                                 
 block4_pool (MaxPooling2D)  (None, 3, 3, 512)         0         
                                                                 
 block5_conv1 (Conv2D)       (None, 3, 3, 512)         2359808   
                                                                 
 block5_conv2 (Conv2D)       (None, 3, 3, 512)         2359808   
                                                                 
 block5_conv3 (Conv2D)       (None, 3, 3, 512)         2359808   
                                                                 
 block5_conv4 (Conv2D)       (None, 3, 3, 512)         2359808   
                                                                 
 block5_pool (MaxPooling2D)  (None, 1, 1, 512)         0         
                                                                 
 flatten (Flatten)           (None, 512)               0         
                                                                 
 dense (Dense)               (None, 2)                 1026      
                                                                 
=================================================================
Total params: 20025410 (76.39 MB)
Trainable params: 20025410 (76.39 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________


model.compile(Adamax(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])

history = model.fit(X_train, Y_train, validation_data = (X_test, Y_test), epochs = 60, batch_size = 35, shuffle=True)

     
Epoch 1/60
9/9 [==============================] - 57s 6s/step - loss: 2.4909 - accuracy: 0.7183 - val_loss: 0.4868 - val_accuracy: 0.8537
Epoch 2/60
9/9 [==============================] - 52s 6s/step - loss: 0.3916 - accuracy: 0.8556 - val_loss: 0.4616 - val_accuracy: 0.8537
Epoch 3/60
9/9 [==============================] - 52s 6s/step - loss: 0.3640 - accuracy: 0.8556 - val_loss: 0.4537 - val_accuracy: 0.8537
Epoch 4/60
9/9 [==============================] - 52s 6s/step - loss: 0.3569 - accuracy: 0.8556 - val_loss: 0.5204 - val_accuracy: 0.8537
Epoch 5/60
9/9 [==============================] - 53s 6s/step - loss: 0.3231 - accuracy: 0.8556 - val_loss: 0.5868 - val_accuracy: 0.8537
Epoch 6/60
9/9 [==============================] - 52s 6s/step - loss: 0.2994 - accuracy: 0.8556 - val_loss: 0.5315 - val_accuracy: 0.8537
Epoch 7/60
9/9 [==============================] - 52s 6s/step - loss: 0.2995 - accuracy: 0.8556 - val_loss: 0.7399 - val_accuracy: 0.8537
Epoch 8/60
9/9 [==============================] - 52s 6s/step - loss: 0.3307 - accuracy: 0.8556 - val_loss: 0.5792 - val_accuracy: 0.8537
Epoch 9/60
9/9 [==============================] - 52s 6s/step - loss: 0.2948 - accuracy: 0.8556 - val_loss: 0.6512 - val_accuracy: 0.8537
Epoch 10/60
9/9 [==============================] - 53s 6s/step - loss: 0.2641 - accuracy: 0.8556 - val_loss: 0.6867 - val_accuracy: 0.8537
Epoch 11/60
9/9 [==============================] - 57s 6s/step - loss: 0.2304 - accuracy: 0.8662 - val_loss: 0.8769 - val_accuracy: 0.8455
Epoch 12/60
9/9 [==============================] - 52s 6s/step - loss: 0.2216 - accuracy: 0.9014 - val_loss: 0.9112 - val_accuracy: 0.8537
Epoch 13/60
9/9 [==============================] - 52s 6s/step - loss: 0.2146 - accuracy: 0.8697 - val_loss: 0.8815 - val_accuracy: 0.8455
Epoch 14/60
9/9 [==============================] - 52s 6s/step - loss: 0.1990 - accuracy: 0.8873 - val_loss: 0.9022 - val_accuracy: 0.8455
Epoch 15/60
9/9 [==============================] - 52s 6s/step - loss: 0.1907 - accuracy: 0.9049 - val_loss: 0.9393 - val_accuracy: 0.8374
Epoch 16/60
9/9 [==============================] - 52s 6s/step - loss: 0.1903 - accuracy: 0.9261 - val_loss: 1.7841 - val_accuracy: 0.8537
Epoch 17/60
9/9 [==============================] - 52s 6s/step - loss: 0.2380 - accuracy: 0.8873 - val_loss: 1.0828 - val_accuracy: 0.8374
Epoch 18/60
9/9 [==============================] - 53s 6s/step - loss: 0.1692 - accuracy: 0.8979 - val_loss: 1.1207 - val_accuracy: 0.8455
Epoch 19/60
9/9 [==============================] - 57s 6s/step - loss: 0.1647 - accuracy: 0.9472 - val_loss: 1.5673 - val_accuracy: 0.8537
Epoch 20/60
9/9 [==============================] - 51s 6s/step - loss: 0.1312 - accuracy: 0.9437 - val_loss: 1.5453 - val_accuracy: 0.8455
Epoch 21/60
9/9 [==============================] - 53s 6s/step - loss: 0.1023 - accuracy: 0.9507 - val_loss: 1.4246 - val_accuracy: 0.8374
Epoch 22/60
9/9 [==============================] - 57s 6s/step - loss: 0.0957 - accuracy: 0.9718 - val_loss: 1.9904 - val_accuracy: 0.8374
Epoch 23/60
9/9 [==============================] - 58s 7s/step - loss: 0.0764 - accuracy: 0.9718 - val_loss: 1.6777 - val_accuracy: 0.8455
Epoch 24/60
9/9 [==============================] - 52s 6s/step - loss: 0.0856 - accuracy: 0.9718 - val_loss: 1.7102 - val_accuracy: 0.7724
Epoch 25/60
9/9 [==============================] - 52s 6s/step - loss: 0.0747 - accuracy: 0.9754 - val_loss: 2.6756 - val_accuracy: 0.8374
Epoch 26/60
9/9 [==============================] - 57s 6s/step - loss: 0.0578 - accuracy: 0.9930 - val_loss: 2.0735 - val_accuracy: 0.8374
Epoch 27/60
9/9 [==============================] - 57s 6s/step - loss: 0.0445 - accuracy: 0.9894 - val_loss: 2.3467 - val_accuracy: 0.8211
Epoch 28/60
9/9 [==============================] - 52s 6s/step - loss: 0.0388 - accuracy: 0.9930 - val_loss: 2.4488 - val_accuracy: 0.8293
Epoch 29/60
9/9 [==============================] - 51s 6s/step - loss: 0.0314 - accuracy: 0.9965 - val_loss: 3.0883 - val_accuracy: 0.8293
Epoch 30/60
9/9 [==============================] - 57s 6s/step - loss: 0.0247 - accuracy: 0.9965 - val_loss: 2.4224 - val_accuracy: 0.8374
Epoch 31/60
9/9 [==============================] - 51s 6s/step - loss: 0.0387 - accuracy: 0.9859 - val_loss: 4.2993 - val_accuracy: 0.8374
Epoch 32/60
9/9 [==============================] - 53s 6s/step - loss: 0.0495 - accuracy: 0.9859 - val_loss: 3.8258 - val_accuracy: 0.8293
Epoch 33/60
9/9 [==============================] - 57s 6s/step - loss: 0.0979 - accuracy: 0.9683 - val_loss: 4.2811 - val_accuracy: 0.8537
Epoch 34/60
9/9 [==============================] - 58s 6s/step - loss: 0.0587 - accuracy: 0.9754 - val_loss: 2.3000 - val_accuracy: 0.8049
Epoch 35/60
9/9 [==============================] - 57s 7s/step - loss: 0.0403 - accuracy: 0.9930 - val_loss: 3.2805 - val_accuracy: 0.8374
Epoch 36/60
9/9 [==============================] - 52s 6s/step - loss: 0.0262 - accuracy: 0.9930 - val_loss: 2.9164 - val_accuracy: 0.8374
Epoch 37/60
9/9 [==============================] - 53s 6s/step - loss: 0.0245 - accuracy: 0.9930 - val_loss: 3.7562 - val_accuracy: 0.8374
Epoch 38/60
9/9 [==============================] - 58s 6s/step - loss: 0.0179 - accuracy: 0.9930 - val_loss: 3.0415 - val_accuracy: 0.8374
Epoch 39/60
9/9 [==============================] - 58s 6s/step - loss: 0.0171 - accuracy: 0.9930 - val_loss: 3.6614 - val_accuracy: 0.8293
Epoch 40/60
9/9 [==============================] - 53s 6s/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 3.1128 - val_accuracy: 0.8537
Epoch 41/60
9/9 [==============================] - 52s 6s/step - loss: 0.0152 - accuracy: 0.9965 - val_loss: 3.7517 - val_accuracy: 0.8293
Epoch 42/60
9/9 [==============================] - 56s 6s/step - loss: 0.0241 - accuracy: 0.9930 - val_loss: 3.3874 - val_accuracy: 0.8293
Epoch 43/60
9/9 [==============================] - 52s 6s/step - loss: 0.0287 - accuracy: 0.9894 - val_loss: 3.0582 - val_accuracy: 0.8455
Epoch 44/60
9/9 [==============================] - 52s 6s/step - loss: 0.0319 - accuracy: 0.9824 - val_loss: 3.5121 - val_accuracy: 0.8211
Epoch 45/60
9/9 [==============================] - 53s 6s/step - loss: 0.0393 - accuracy: 0.9824 - val_loss: 2.8427 - val_accuracy: 0.8455
Epoch 46/60
9/9 [==============================] - 51s 6s/step - loss: 0.0517 - accuracy: 0.9754 - val_loss: 3.5603 - val_accuracy: 0.8618
Epoch 47/60
9/9 [==============================] - 53s 6s/step - loss: 0.0810 - accuracy: 0.9824 - val_loss: 3.2099 - val_accuracy: 0.8455
Epoch 48/60
9/9 [==============================] - 52s 6s/step - loss: 0.0430 - accuracy: 0.9824 - val_loss: 2.0319 - val_accuracy: 0.8374
Epoch 49/60
9/9 [==============================] - 53s 6s/step - loss: 0.0377 - accuracy: 0.9894 - val_loss: 3.4943 - val_accuracy: 0.8618
Epoch 50/60
9/9 [==============================] - 57s 6s/step - loss: 0.0354 - accuracy: 0.9894 - val_loss: 2.3257 - val_accuracy: 0.8211
Epoch 51/60
9/9 [==============================] - 53s 6s/step - loss: 0.0165 - accuracy: 0.9965 - val_loss: 3.3261 - val_accuracy: 0.8130
Epoch 52/60
9/9 [==============================] - 50s 6s/step - loss: 0.0132 - accuracy: 0.9965 - val_loss: 3.3130 - val_accuracy: 0.8293
Epoch 53/60
9/9 [==============================] - 58s 6s/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 3.7551 - val_accuracy: 0.8211
Epoch 54/60
9/9 [==============================] - 51s 6s/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 3.2452 - val_accuracy: 0.8293
Epoch 55/60
9/9 [==============================] - 52s 6s/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 3.6672 - val_accuracy: 0.8130
Epoch 56/60
9/9 [==============================] - 58s 6s/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 3.6409 - val_accuracy: 0.8293
Epoch 57/60
9/9 [==============================] - 51s 6s/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 4.0135 - val_accuracy: 0.8211
Epoch 58/60
9/9 [==============================] - 52s 6s/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 3.8855 - val_accuracy: 0.8130
Epoch 59/60
9/9 [==============================] - 56s 6s/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 3.7995 - val_accuracy: 0.8293
Epoch 60/60
9/9 [==============================] - 53s 6s/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 3.9391 - val_accuracy: 0.8293


# Mount Google Drive
from google.colab import drive
drive.mount('/content/drive')

# Save your model to a folder named 'models' in your Google Drive
model.save('/content/drive/MyDrive/vgg_19model/deepfake_vgg_19.h5')

     
Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount("/content/drive", force_remount=True).
/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning:

You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.


plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Model Accuracy')
plt.xlabel('epoch')
plt.ylabel('accuracy')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Model Loss')
plt.xlabel('epoch')
plt.ylabel('loss')
plt.legend(['train', 'test'], loc='upper left')
plt.show()
     



model.evaluate(X_test,Y_test)
     
4/4 [==============================] - 5s 1s/step - loss: 3.9391 - accuracy: 0.8293
[3.9390718936920166, 0.8292682766914368]

from sklearn.metrics import accuracy_score
Y_pred = model.predict(X_test)
Y_pred_classes = np.argmax(Y_pred,axis = 1)
Y_true = np.argmax(Y_test,axis = 1)
#accuracy=accuracy_score(y_true=Y_true, y_pred=Y_pred)
#print(accuracy)
confusion_mtx = confusion_matrix(Y_true, Y_pred_classes)
f,ax = plt.subplots(figsize=(8,5))
sns.heatmap(confusion_mtx, annot=True, linewidths=0.01,cmap="BuPu",linecolor="gray", fmt= '.1f',ax=ax)
plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.title("Confusion Matrix")
plt.show()

     
4/4 [==============================] - 9s 2s/step


from sklearn.metrics import accuracy_score, confusion_matrix
#Y_pred = model.predict(X_test)
Y_pred_classes = np.argmax(Y_pred, axis=1)
Y_true = np.argmax(Y_test, axis=1)

confusion_mtx = confusion_matrix(Y_true, Y_pred_classes)

# calculate the percentage
confusion_mtx_percent = confusion_mtx.astype('float') / confusion_mtx.sum(axis=1)[:, np.newaxis] * 100

f, ax = plt.subplots(figsize=(8, 5))
sns.heatmap(confusion_mtx_percent, annot=True, linewidths=0.01, cmap="BuPu", linecolor="gray", fmt='.1f', ax=ax)
plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.title("Confusion Matrix (Percentage)")
plt.show()


     


def img_plot(arr,index=0):
    plt.title('Test Image')
    plt.imshow(arr[index])

# Get the length of the array
n = len(X_test)

# Loop over the indices from 0 to n-1
for i in range(n):
    # Plot the image at each index
    img_plot(X_test, i)

     


import random

def img_plot(arr,index=0):
    plt.title('Test Image')
    plt.imshow(arr[index])

# Get the length of the array
n = len(X_test)

# Get a random index within the range
index = random.randint(0, n-1)

# Get the input data as a numpy array
input = np.array([X_test[index]])
# Predict the label using the model
pred = model.predict(input)[0].argmax
# Get the true label
label = Y_test[index].argmax
# Print the results
print('Predicted Value using cnn model',pred)
print("True Value",label)
# Plot the image
img_plot(X_test, index)

     
1/1 [==============================] - 0s 161ms/step
Predicted Value using cnn model <built-in method argmax of numpy.ndarray object at 0x7c6fb0aab8d0>
True Value <built-in method argmax of numpy.ndarray object at 0x7c6f9bd487b0>
